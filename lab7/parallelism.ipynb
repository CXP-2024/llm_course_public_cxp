{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb0f1de",
   "metadata": {},
   "source": [
    "## Running on multiple GPUs using Hugging Face Transformers\n",
    "\n",
    "Naive pipeline parallelism is supported out of the box. For this, simply load the model with device=\"auto\" which will automatically place the different layers on the available GPUs.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Create a pod with two 24GB GPUs.\n",
    "\n",
    "2. Try to run the model with device=\"auto\" and see how much VRAM is used. You can also try to run the model with device_map=\"auto\" which will automatically place the different layers on the available GPUs. This is a more advanced version of pipeline parallelism that allows for more flexibility in how the model is distributed across GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04b442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始GPU内存状态:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "      <th>used</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24564.0</td>\n",
       "      <td>453.125</td>\n",
       "      <td>24110.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24564.0</td>\n",
       "      <td>453.125</td>\n",
       "      <td>24110.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    total     used       free\n",
       "0   0  24564.0  453.125  24110.875\n",
       "1   1  24564.0  453.125  24110.875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "加载模型到单个GPU (device=0):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a803b7a0496d44cbbab40db1af4006ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "      <th>used</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24564.0</td>\n",
       "      <td>16165.3125</td>\n",
       "      <td>8398.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24564.0</td>\n",
       "      <td>456.0000</td>\n",
       "      <td>24108.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    total        used        free\n",
       "0   0  24564.0  16165.3125   8398.6875\n",
       "1   1  24564.0    456.0000  24108.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPU ID</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15712.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GPU ID  Memory Used (MB)\n",
       "0       0        15712.1875\n",
       "1       1            2.8750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用device_map=\"auto\"加载模型:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164e3b16f5d84fce9f4d955cc28bd1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "      <th>used</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24564.0</td>\n",
       "      <td>7675.3125</td>\n",
       "      <td>16888.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24564.0</td>\n",
       "      <td>9339.3125</td>\n",
       "      <td>15224.6875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    total       used        free\n",
       "0   0  24564.0  7675.3125  16888.6875\n",
       "1   1  24564.0  9339.3125  15224.6875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPU ID</th>\n",
       "      <th>Memory Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7222.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8886.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GPU ID  Memory Used (MB)\n",
       "0       0         7222.1875\n",
       "1       1         8886.1875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型分布在以下设备上 (auto):\n",
      "{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}\n",
      "\n",
      "总结:\n",
      "单GPU加载内存使用: GPU 0: 15712.19 MB\n",
      "device_map=\"auto\"内存使用: GPU 0: 7222.19 MB\n",
      "device_map=\"auto\"内存使用: GPU 1: 8886.19 MB\n",
      "使用的GPU数量: 2\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/ssdshare/share/Meta-Llama-3-8B-Instruct/\"\n",
    "# TODO(Your Task): Load the model to multiple GPUs and check the GPU memory usage\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from pynvml import *\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"获取每个GPU的内存使用情况\"\"\"\n",
    "    nvmlInit()\n",
    "    gpu_info = []\n",
    "    device_count = nvmlDeviceGetCount()\n",
    "    \n",
    "    for i in range(device_count):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        gpu_info.append({\n",
    "            'id': i,\n",
    "            'total': info.total / 1024**2,  # MB\n",
    "            'used': info.used / 1024**2,    # MB\n",
    "            'free': info.free / 1024**2     # MB\n",
    "        })\n",
    "    \n",
    "    nvmlShutdown()\n",
    "    return pd.DataFrame(gpu_info)\n",
    "\n",
    "# 检查初始GPU内存状态\n",
    "print(\"初始GPU内存状态:\")\n",
    "initial_gpu_memory = get_gpu_memory()\n",
    "display(initial_gpu_memory)\n",
    "\n",
    "# 1. 加载模型到单个GPU\n",
    "print(\"\\n加载模型到单个GPU (device=0):\")\n",
    "torch.cuda.empty_cache()\n",
    "single_gpu_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "single_gpu_memory = get_gpu_memory()\n",
    "display(single_gpu_memory)\n",
    "single_gpu_usage = single_gpu_memory['used'] - initial_gpu_memory['used']\n",
    "display(pd.DataFrame({'GPU ID': single_gpu_memory['id'], 'Memory Used (MB)': single_gpu_usage}))\n",
    "del single_gpu_model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. 使用device_map=\"balanced\"加载模型 (替代device=\"auto\")\n",
    "# print(\"\\n使用device_map=\\\"balanced\\\"加载模型:\")\n",
    "# torch.cuda.empty_cache()\n",
    "# balanced_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path, \n",
    "#     torch_dtype=torch.bfloat16, \n",
    "#     device_map=\"balanced\"\n",
    "# )\n",
    "# balanced_memory = get_gpu_memory()\n",
    "# display(balanced_memory)\n",
    "# balanced_usage = balanced_memory['used'] - initial_gpu_memory['used']\n",
    "# display(pd.DataFrame({'GPU ID': balanced_memory['id'], 'Memory Used (MB)': balanced_usage}))\n",
    "# print(\"\\n模型分布在以下设备上 (balanced):\")\n",
    "# print(balanced_model.hf_device_map)\n",
    "# del balanced_model\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# 3. 使用device_map=\"auto\"加载模型\n",
    "print(\"\\n使用device_map=\\\"auto\\\"加载模型:\")\n",
    "torch.cuda.empty_cache()\n",
    "auto_map_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "auto_map_memory = get_gpu_memory()\n",
    "display(auto_map_memory)\n",
    "auto_map_usage = auto_map_memory['used'] - initial_gpu_memory['used']\n",
    "display(pd.DataFrame({'GPU ID': auto_map_memory['id'], 'Memory Used (MB)': auto_map_usage}))\n",
    "\n",
    "# 显示模型在哪些设备上\n",
    "print(\"\\n模型分布在以下设备上 (auto):\")\n",
    "print(auto_map_model.hf_device_map)\n",
    "\n",
    "print(\"\\n总结:\")\n",
    "print(f\"单GPU加载内存使用: GPU 0: {single_gpu_usage[0]:.2f} MB\")\n",
    "for i in range(len(auto_map_usage)):\n",
    "    print(f\"device_map=\\\"auto\\\"内存使用: GPU {i}: {auto_map_usage[i]:.2f} MB\") \n",
    "print(f\"使用的GPU数量: {torch.cuda.device_count()}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d168c7",
   "metadata": {},
   "source": [
    "The GPU memory usage of loading the model to only one GPU is 15712.19MB.\n",
    "\n",
    "The GPU memory usage of loading the model with device=\"auto\" is \\_\\_\\_(This always says error). The GPU memory usage of loading the model with device_map=\"auto\" is 7.2+8.5=16GB.\n",
    "\n",
    "The number of GPUs you used is 2.\n",
    "\n",
    "Does the numbers above make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa1689",
   "metadata": {},
   "source": [
    "Yes, the numbers make sense. When using `device_map=\"auto\"`, the model is distributed across the available GPUs. The GPU memory usage I observed aligns with the expected behavior of distributing the model layers across multiple GPUs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
