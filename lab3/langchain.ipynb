{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec3. LangChain\n",
    "\n",
    "\n",
    "**LangChain** is a framework for developing applications powered by language models. It provides abundant abstractions about langage models and sources of context (prompt instructions, few shot examples, content to ground its response in, etc.), which enable the user to easily **chain** these components together for developing awesome applications.\n",
    "\n",
    "In this lab, we will learn several key abstractions in LangChain and build an input-output customized AI-powered web-search application.\n",
    "\n",
    "### Reference \n",
    "1. [Langchain document](https://python.langchain.com/docs/introduction/)\n",
    "\n",
    "\n",
    "## 0. First thing first\n",
    "\n",
    "### 0.1 Dependencies and Keys\n",
    "  \n",
    "In addition to the Open AI keys, add the following keys to your .env file.\n",
    "\n",
    "- Serp api key:\n",
    "    ```\n",
    "    SERPAPI_API_KEY=\"YOURKEY\"\n",
    "    ```\n",
    "    The `SERPAPI_API_KEY` is for invoking the search engine, first register through this [web site](https://serpapi.com/).\n",
    "\n",
    "    After getting these two keys, set your keys as environment variables.\n",
    "- Langchain API key (for tracing)\n",
    "    ```\n",
    "    LANGCHAIN_TRACING_V2=\"true\"\n",
    "    LANGCHAIN_API_KEY=ls_xxxxxxxx\n",
    "    ```\n",
    "    To create a `LANGCHAIN_API_KEY`, you can register through the [LANGSMITH](https://docs.smith.langchain.com/)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have installed these dependencies in your image\n",
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv  \n",
    "import os  \n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "# os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "# os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL=\"qwen2.5-72b-instruct\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.environ.get(\"INFINI_API_KEY\")  # langchain use this environment variable to find the OpenAI API key\n",
    "OPENAI_BASE=os.environ.get(\"INFINI_BASE_URL\") # will be used to pass the OpenAI base URL to langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Key abstractions in LangChain\n",
    "\n",
    "| Abstracted Components | Input Type                                | Output Type           |\n",
    "|-----------------------|-------------------------------------------|-----------------------|\n",
    "| Prompt                | Dictionary                                | PromptValue           |\n",
    "| ChatModel             | string, list of messages or a PromptValue | string, ChatMessage   |\n",
    "| OutputParser          | The output of an LLM or ChatModel         | Depends on the parser |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The ChatModel\n",
    "\n",
    "`ChatModels` is a language model which takes a list of messages or a string as input and returns a message or a string.\n",
    "\n",
    "`ChatModel` provides two methods to interact with the user:\n",
    "\n",
    "- `predict`: takes in a string, returns a string.\n",
    "- `predict_messages`: takes in a list of messages, returns a message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat_model = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=CHAT_MODEL,\n",
    "    base_url=OPENAI_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an output utility to show the type and the content of the result\n",
    "def print_with_type(res):\n",
    "    print(f\"%s\" % (type(res)))\n",
    "    print(f\"%s\" % res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four roles in LangChain, and you can define your own custom roles.\n",
    "\n",
    "- `HumanMessage`: A ChatMessage coming from a human/user.\n",
    "- `AIMessage`: A ChatMessage coming from an AI/assistant.\n",
    "- `SystemMessage`: A ChatMessage coming from the system.\n",
    "- `FunctionMessage`: A ChatMessage coming from a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='Hello Xu Wei! Nice to meet you too! I\\'d be happy to tell you about LangChain.\\n\\nLangChain is a framework designed to help developers build applications that leverage large language models (LLMs) like me. It provides a set of tools and abstractions that make it easier to integrate LLMs into various applications, from chatbots and content generators to more complex systems that require natural language understanding and generation.\\n\\n### Key Features of LangChain:\\n1. **Modular Design**: LangChain is built with a modular architecture, allowing developers to mix and match different components to suit their specific needs. This includes different language models, data sources, and output formats.\\n\\n2. **Chain of Thought**: One of the core concepts in LangChain is the \"Chain of Thought\" (CoT) pattern. This involves breaking down complex tasks into a series of simpler steps, each of which can be handled by a language model. This approach helps in improving the accuracy and reliability of the model\\'s outputs.\\n\\n3. **Data Integration**: LangChain supports integration with various data sources, including databases, APIs, and file systems. This allows the language model to access and use external data to generate more informed and contextually relevant responses.\\n\\n4. **Customization**: Developers can customize the behavior of the language model by defining custom prompts, templates, and logic. This flexibility is crucial for tailoring the model to specific use cases and domains.\\n\\n5. **Security and Privacy**: LangChain includes features to help ensure the security and privacy of data. This is particularly important when dealing with sensitive information.\\n\\n6. **Community and Ecosystem**: LangChain has a growing community of developers and contributors. This community provides support, shares best practices, and develops additional tools and plugins that extend the functionality of the framework.\\n\\n### Use Cases:\\n- **Chatbots**: Building conversational agents that can engage in natural language conversations with users.\\n- **Content Generation**: Generating articles, blog posts, and other types of content.\\n- **Code Generation**: Assisting developers by generating code snippets or entire functions.\\n- **Data Analysis**: Analyzing and summarizing large datasets.\\n- **Personal Assistants**: Creating personal assistants that can help with tasks like scheduling, reminders, and information retrieval.\\n\\n### Getting Started:\\nIf you\\'re interested in using LangChain, you can start by checking out the official documentation and tutorials. The documentation provides detailed guides on how to set up the framework, integrate different language models, and build your first application.\\n\\nI hope this gives you a good overview of LangChain! If you have any more questions or need further details, feel free to ask!' response_metadata={'token_usage': {'completion_tokens': 530, 'prompt_tokens': 50, 'total_tokens': 580}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}} id='run-ae5a0270-7c7e-4301-8a59-ac4d77a82714-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "qtext = \"hello! my name is xu wei, nice to meet you! could you tell me something about langchain\"\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "    HumanMessage(content=qtext)  # construct a human message\n",
    "    )\n",
    "res = chat_model.invoke(messages)  # invoke the chat model\n",
    "\n",
    "print_with_type(res)\n",
    "\n",
    "messages.append(res)  # append the result to the chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructors are tedious to use, and you can use the following more friendly API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content=\"I'm just here to help you out! What can I assist you with today?\" response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 50, 'total_tokens': 68}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}} id='run-7bd0437b-40f1-44b3-b153-b27d7c1b1a07-0'\n"
     ]
    }
   ],
   "source": [
    "# a simpler way to manage messages\n",
    "from langchain.memory import ChatMessageHistory\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")  # avoid using the constructor directly\n",
    "history.add_ai_message(\"whats up?\")\n",
    "history.add_user_message(\"nothing much, you?\")\n",
    "\n",
    "res = chat_model.invoke(history.messages)\n",
    "print_with_type(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content=\"LangChain has a wide range of applications across various industries and use cases. Here are some of the key areas where LangChain can be particularly useful:\\n\\n### 1. **Chatbots and Virtual Assistants**\\n- **Customer Support**: Building chatbots that can handle customer inquiries, provide product information, and assist with troubleshooting.\\n- **Personal Assistants**: Creating virtual assistants that can manage schedules, set reminders, and perform tasks on behalf of users.\\n\\n### 2. **Content Generation**\\n- **Article Writing**: Generating articles, blog posts, and news updates.\\n- **Social Media Posts**: Creating engaging social media content.\\n- **Marketing Copy**: Writing marketing materials, product descriptions, and ad copy.\\n\\n### 3. **Code Generation and Assistance**\\n- **Code Snippets**: Generating code snippets for specific tasks or problems.\\n- **Documentation**: Writing documentation for code and APIs.\\n- **Code Review**: Providing suggestions and feedback on code quality.\\n\\n### 4. **Data Analysis and Reporting**\\n- **Data Summarization**: Summarizing large datasets and providing insights.\\n- **Report Generation**: Creating detailed reports and visualizations.\\n- **Predictive Analytics**: Using language models to make predictions based on historical data.\\n\\n### 5. **Educational Tools**\\n- **Tutoring Systems**: Building systems that can provide personalized tutoring and feedback.\\n- **Content Creation**: Generating educational content, quizzes, and exercises.\\n- **Language Learning**: Creating tools to help users learn new languages.\\n\\n### 6. **E-commerce and Retail**\\n- **Product Recommendations**: Providing personalized product recommendations based on user preferences and behavior.\\n- **Customer Reviews**: Generating and summarizing customer reviews.\\n- **Inventory Management**: Assisting with inventory management and stock updates.\\n\\n### 7. **Healthcare**\\n- **Patient Engagement**: Building chatbots that can provide health information, appointment reminders, and symptom checkers.\\n- **Medical Documentation**: Assisting healthcare professionals in writing and summarizing medical records.\\n- **Research Assistance**: Helping researchers by summarizing and analyzing medical literature.\\n\\n### 8. **Legal and Compliance**\\n- **Contract Review**: Assisting in the review and summarization of legal documents.\\n- **Compliance Checking**: Ensuring that documents and processes comply with regulations.\\n- **Legal Research**: Providing assistance in legal research and case analysis.\\n\\n### 9. **Financial Services**\\n- **Financial Advice**: Providing personalized financial advice and investment recommendations.\\n- **Risk Assessment**: Analyzing and assessing financial risks.\\n- **Report Generation**: Creating financial reports and summaries.\\n\\n### 10. **Gaming and Entertainment**\\n- **NPC Dialogue**: Generating dialogue for non-player characters (NPCs) in video games.\\n- **Story Generation**: Creating dynamic and engaging storylines for games and interactive media.\\n- **Content Moderation**: Assisting in the moderation of user-generated content.\\n\\n### 11. **Research and Development**\\n- **Literature Review**: Summarizing and analyzing research papers and articles.\\n- **Hypothesis Generation**: Assisting in the generation of research hypotheses.\\n- **Data Analysis**: Providing insights and analysis for research projects.\\n\\n### 12. **Customer Experience**\\n- **Feedback Analysis**: Analyzing customer feedback and reviews to identify trends and areas for improvement.\\n- **Survey Creation**: Generating and analyzing surveys to gather customer insights.\\n- **Personalization**: Tailoring customer experiences based on individual preferences and behavior.\\n\\n### 13. **Human Resources**\\n- **Recruitment**: Assisting in the recruitment process by generating job descriptions, screening resumes, and conducting initial interviews.\\n- **Employee Onboarding**: Creating onboarding materials and providing support to new employees.\\n- **Performance Reviews**: Assisting in the creation and analysis of performance reviews.\\n\\n### 14. **Marketing and Sales**\\n- **Lead Generation**: Generating leads and qualifying potential customers.\\n- **Sales Support**: Providing sales teams with product information, customer insights, and sales strategies.\\n- **Campaign Analysis**: Analyzing marketing campaigns and providing insights for optimization.\\n\\n### 15. **Customer Service**\\n- **Ticket Management**: Assisting in the management of customer support tickets.\\n- **FAQ Generation**: Creating and maintaining frequently asked questions (FAQs).\\n- **Customer Feedback**: Collecting and analyzing customer feedback to improve services.\\n\\n### Conclusion\\nLangChain's flexibility and modular design make it a powerful tool for a wide range of applications. Whether you're building a chatbot, generating content, or analyzing data, LangChain can help you leverage the power of large language models to create more efficient and effective solutions. If you have a specific use case in mind, feel free to share more details, and I can provide more tailored advice!\" response_metadata={'token_usage': {'completion_tokens': 948, 'prompt_tokens': 594, 'total_tokens': 1542}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}} id='run-2be8f1c4-a98f-46ec-ae7b-a7a27f1dbfac-0'\n"
     ]
    }
   ],
   "source": [
    "# remembering the chat history and context\n",
    "\n",
    "qtext = \"what is its application?\"\n",
    "messages.append(HumanMessage(content=qtext))  ## providing context of chat histroy\n",
    "res = chat_model.invoke(messages)\n",
    "print_with_type(res)\n",
    "messages.append(res)  ## remembers the histroy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prompt templates\n",
    "\n",
    "LangChain provides ``PromptTemplate`` to help with formatting the prompts. \n",
    "A ``PromptTemplate`` allows you to define a template with placeholders that can be filled in with specific values at runtime. \n",
    "This helps in creating dynamic and reusable prompts for different contexts and inputs.\n",
    "\n",
    "The most plain prompt is in the type of a ``string``. Usually, the prompt includes several different type of `Messages`, which contains the `role` and the plain prompt as `content`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Simple template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "What is a good name for a company that makes candies?\n"
     ]
    }
   ],
   "source": [
    "# Prompt Template\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "input_prompt = prompt.format(product=\"candies\")\n",
    "\n",
    "print_with_type(input_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[SystemMessage(content='You are a helpful assistant that translates English to Chinese.'), HumanMessage(content='I love programming.')]\n"
     ]
    }
   ],
   "source": [
    "# Chat Template (a list of temlates in a chat prompt template)\n",
    "\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "# format chat message prompt\n",
    "sys_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chat_input = chat_prompt.format_messages(input_language=\"English\", output_language=\"Chinese\", text=\"I love programming.\")\n",
    "\n",
    "print_with_type(chat_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Using template in the chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[SystemMessage(content='You are a helpful assistant that translates English to Chinese.'), HumanMessage(content='what is its application?')]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='它的应用是什么？' response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 29, 'total_tokens': 34}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}} id='run-69ae8050-289f-40ef-b675-7d065765faad-0'\n"
     ]
    }
   ],
   "source": [
    "# format messages with PromptTemplate with translator as an example\n",
    "messages = []\n",
    "chat_input = chat_prompt.format_messages(input_language=\"English\", output_language=\"Chinese\", text=qtext)\n",
    "print_with_type(chat_input)\n",
    "print_with_type(chat_model.invoke(chat_input))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[SystemMessage(content='You are a helpful assistant that translates English to Chinese.'), HumanMessage(content='what is its application?')]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='它的应用是什么？' response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 29, 'total_tokens': 34}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}} id='run-c9875c76-3c2f-4121-88f1-32c70f9d0052-0'\n"
     ]
    }
   ],
   "source": [
    "messages = chat_input + messages  ## the system message must be at the beginning\n",
    "print_with_type(messages)\n",
    "\n",
    "res = chat_model.invoke(messages)\n",
    "print_with_type(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Chaining Components together\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components. \n",
    "In LangChain, most of the above key abstraction components are `Runnable` objects, and we can **chain** them together to build awesome applications. \n",
    "\n",
    "LangChain makes the chainning powerful through **LangChain Expression Language (LCEL)**, which can support chainning in manners of:\n",
    "\n",
    "- Async, Batch, and Streaming Support: any chain constructed in LCEL can automatically have full synv, async, batch and streaming support. \n",
    "- Fallbacks: due to many factors like network connection or non-deterministic properties, your LLM applications need to handle errors gracefully. With LCEL, your can easily attach fallbacks any chain.\n",
    "- Parallelism: since LLM applications involve (sometimes long) API calls, it often becomes important to run things in parallel. With LCEL syntax, any components that can be run in parallel automatically are.\n",
    "- LangSmith Tracing Integration: (for debugging, see below).\n",
    "\n",
    "In this lab, we only demonstrate the simplest functional chainning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='{\"这是输入到聊天模型链和聊天提示的内容。\"}' response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 39, 'total_tokens': 53}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}} id='run-66a2a81c-1bcc-4187-a8cd-2fa7e1dd0454-0'\n"
     ]
    }
   ],
   "source": [
    "# More abstractions: bundling prompt and the chat_model into a chain\n",
    "\n",
    "translate_chain = chat_prompt | chat_model\n",
    "qtext = \"this is input to a chain of chat model and chat prompt.\"\n",
    "out = translate_chain.invoke({\n",
    "    \"input_language\": \"English\", \n",
    "    \"output_language\": \"Chinese\", \n",
    "    \"text\": {qtext}\n",
    "    })\n",
    "print_with_type(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Output parser\n",
    "\n",
    "Language models output text, which is often unstructured and free-form. However, in many applications, you may need more structured information to work with, such as JSON, XML, or other formats. This is where output parsers come in.\n",
    "\n",
    "Output parsers are tools that transform the raw text output of language models into structured data formats. The motivation for using output parsers is to facilitate easier data manipulation, integration, and analysis. By converting text into structured formats, you can more effectively utilize the information in downstream applications, automate workflows, and ensure consistency in data handling.\n",
    "\n",
    "LangChain provides several commonly-used output parsers, including:\n",
    "- [JSONparser](https://python.langchain.com/docs/how_to/output_parser_json/): Converts text output into JSON format.\n",
    "- [XMLparser](https://python.langchain.com/docs/how_to/output_parser_xml/): Converts text output into XML format.\n",
    "- [YAMLparser](https://python.langchain.com/docs/how_to/output_parser_yaml/): Converts text output into YAML format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Simple output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\"这是输入到聊天模型链和聊天提示的内容。\"}\n"
     ]
    }
   ],
   "source": [
    "# a simple output parser\n",
    "# StdOutParser converts the chat message to a string.\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "stdoutchain = chat_prompt | chat_model | output_parser\n",
    "\n",
    "qtext = \"this is input to a chain of chat model and chat prompt.\"\n",
    "out=stdoutchain.invoke({\n",
    "    \"input_language\": \"English\", \n",
    "    \"output_language\": \"Chinese\", \n",
    "    \"text\": {qtext}\n",
    "    })\n",
    "print_with_type(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Advanced output parsers: from Results to a Python Object\n",
    "Here we demonstrate the powerful Json Outputparser as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'name': 'Wei Xu', 'publications': 'A Survey of Deep Learning System Optimization, Deep Learning-based Text Representation: A Survey, Efficient and Effective Algorithms for Training Quantized Neural Networks, and more'}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Professor(BaseModel):\n",
    "    name: str = Field(description=\"name of the Professor\")\n",
    "    publications: str = Field(description=\"the string of the professor's publications, separated by comma\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Professor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "professor_chain = prompt | chat_model | parser\n",
    "query = \"tell me about professor Wei Xu including his publications.\"\n",
    "output = professor_chain.invoke({\n",
    "    \"query\": {query}\n",
    "    })\n",
    "print_with_type(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Answer the user query.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"name of the Professor\", \"title\": \"Name\", \"type\": \"string\"}, \"publications\": {\"description\": \"the string of the professor's publications, separated by comma\", \"title\": \"Publications\", \"type\": \"string\"}}, \"required\": [\"name\", \"publications\"]}\n",
      "```\n",
      "tell me about professor Wei Xu including his publications.\n"
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# see how langchain organizes the input to construct the result.\n",
    "# you can do so by printing the input of the chat_model.\n",
    "input_prompt = prompt.format(query=\"tell me about professor Wei Xu including his publications.\")\n",
    "print_with_type(input_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the list of papers lacks substantial information and contains many inaccuracies. \n",
    "\n",
    "This is because the model has no knowlege about Prof. Wei Xu.  \n",
    "\n",
    "We will now demonstrate how to address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding more contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Allowing the model to search the web: Retrievers\n",
    "\n",
    "Many LLM applications require user-specific data that is not part of the model's training set, like the above example : )\n",
    "The primary way of accomplishing this is through **Retrieval Augmented Generation (RAG)**. In this process, external data is retrieved and then passed to the LLM when doing the generation step. `Retriever` is an interface that returns documents given an unstructured query, which is used to provide the related contents to LLMs\n",
    "\n",
    "LangChain provides all the building blocks for RAG applications - from simple to complex, including document loaders, text embedding models and web searches.  We will introduce these models in Lab 4.  Here, we introduce three very basic retrievers that does web search and some local file access.  \n",
    "\n",
    "- [web page](https://python.langchain.com/docs/how_to/document_loader_web/)\n",
    "- [load Json](https://python.langchain.com/docs/how_to/document_loader_json/)\n",
    "- [load PDF files](https://python.langchain.com/docs/how_to/document_loader_pdf/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SerpAPI is a widely used API to access search engine results. It allows you to scrape and parse search engine data, providing a way to retrieve up-to-date information from the web.\n",
    "\n",
    "In LangChain, SerpAPI can be integrated as a retriever to enhance the capabilities of language models by providing them with the latest information from the web. This is particularly useful for applications that require current data that is not part of the model's training set.\n",
    "\n",
    "By using SerpAPI with LangChain, you can perform web searches and feed the retrieved data into the language model to generate more accurate and contextually relevant responses.\n",
    "\n",
    "In the following sections, we will demonstrate how to set up and use SerpAPI within LangChain to perform web searches and integrate the results into your language model workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'title': \"Nvidia Stock Held Up Better Than Mag 7 Peers During Thursday's Rout—Watch These Key Levels\", 'link': 'https://www.investopedia.com/nvidia-stock-held-up-better-than-mag-7-peers-during-thursday-rout-watch-these-key-levels-11696055', 'source': 'Investopedia', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24b43c2f81805cf6b5b3be5815be8f76320.jpeg'}, {'title': 'Nvidia Stock Is Cheaper Than These 17 Stocks. What to Consider Before Selling Shares.', 'link': 'https://www.barrons.com/articles/nvidia-stock-price-cheaper-buy-sell-e3eb88d7', 'source': \"Barron's\", 'date': '11 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24b4c7b0aaf8781d047769a910f60ccdbb5.jpeg'}, {'title': 'Fund manager sends blunt message on Nvidia stock before conference', 'link': 'https://www.thestreet.com/investing/stocks/veteran-fund-managers-blunt-take-on-nvidia-raises-eyebrows', 'source': 'TheStreet', 'date': '12 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24bc3f521adf0ee9f31107994e50c988a68.jpeg'}, {'title': 'GeForce RTX 5070 Takes The Number One Spot On Amazon, More NVIDIA GPUs Replace AMD In Best Selling GPUs List', 'link': 'https://wccftech.com/geforce-rtx-5070-takes-the-number-one-spot-on-amazon/', 'source': 'Wccftech', 'date': '10 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24bfae7f5d60d411131c3c58ec69e5546a1.jpeg'}, {'title': \"NVIDIA claims to have shipped twice as many RTX 50 cards as RTX 40 since launch, but it's an unfair comparison\", 'link': 'https://videocardz.com/newz/nvidia-claims-to-have-shipped-twice-as-many-rtx-50-cards-as-rtx-40-since-launch-but-its-an-unfair-comparison', 'source': 'VideoCardz.com', 'date': '10 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24babd727336341ea3db8d3f4b7e073af98.jpeg'}, {'title': 'Nvidia’s next chips are named after Vera Rubin, astronomer who discovered dark matter', 'link': 'https://www.cnbc.com/2025/03/13/nvidia-to-detail-vera-rubin-chips-at-gtc-conference.html', 'source': 'CNBC', 'date': '7 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24b66fb3dbf7d1dd2bb5aaa3616b9d0b852.jpeg'}, {'title': \"Nvidia's Huang, critics were wrong about quantum computing: D-Wave CEO\", 'link': 'https://finance.yahoo.com/video/nvidias-huang-critics-were-wrong-170000181.html', 'source': 'Yahoo Finance', 'date': '7 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d377de2da0ac27a5eecc8d/images/1facaa3a5b60e24b8138a12753d5821b3cc4677d8b5018de.jpeg', 'label': 'Video'}]\n"
     ]
    }
   ],
   "source": [
    "# Using the search API\n",
    "\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "results = search.run(\"Nvidia\")\n",
    "print_with_type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the search and LLM together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'title': 'NVIDIA: The Engine of Global AI Infrastructure', 'brief_desc': \"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries estimated at $100 trillion.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "class News(BaseModel):\n",
    "    title: str = Field(description=\"title of the news\")\n",
    "    brief_desc: str = Field(description=\"brief descrption of the corresponding news\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=News)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query based on the following context: \\n{context}\\n{format_instructions}\\nQuery: {query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_model.temperature = 0\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "setup_and_retrieval = {\n",
    "        \"context\": search.run,  # passing a retriever\n",
    "        \"query\": RunnablePassthrough()\n",
    "}\n",
    "websearch_chain = setup_and_retrieval | prompt | chat_model | parser\n",
    "\n",
    "res = websearch_chain.invoke(\"tell me about the nvidia companies, and write a brief summary for it\")\n",
    "\n",
    "print_with_type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Debugging and Logging\n",
    "\n",
    "#### 2.2.1 The debug mode\n",
    "\n",
    "LangChain provides a ``debug`` mode that allows you to see detailed information about the execution of your chains and agents. When debug mode is enabled, LangChain will print verbose output showing:\n",
    "\n",
    "1. The exact prompts being sent to the LLM\n",
    "2. The raw responses received from the LLM\n",
    "3. The execution flow of chains and agents\n",
    "4. Any intermediate steps and tool calls\n",
    "\n",
    "This is extremely useful for:\n",
    "- Troubleshooting unexpected outputs\n",
    "- Understanding how your chains are processing data\n",
    "- Optimizing prompts\n",
    "- Identifying errors in your chain's logic\n",
    "\n",
    "You can enable debug mode using `set_debug(True)` and disable it with `set_debug(False)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:run] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:RunnablePassthrough] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:run] [3.54s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"NVIDIA is the engine of the world's AI infrastructure. Companies and countries around the world are building NVIDIA-powered AI factories to process, refine, and manufacture intelligence from data, creating new revenue opportunities for the world's $100 trillion of industries.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query>] [3.55s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"context\": \"NVIDIA is the engine of the world's AI infrastructure. Companies and countries around the world are building NVIDIA-powered AI factories to process, refine, and manufacture intelligence from data, creating new revenue opportunities for the world's $100 trillion of industries.\",\n",
      "  \"query\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"context\": \"NVIDIA is the engine of the world's AI infrastructure. Companies and countries around the world are building NVIDIA-powered AI factories to process, refine, and manufacture intelligence from data, creating new revenue opportunities for the world's $100 trillion of industries.\",\n",
      "  \"query\": \"tell me about the company nvidia, and write a brief summary for it\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query based on the following context: \\nNVIDIA is the engine of the world's AI infrastructure. Companies and countries around the world are building NVIDIA-powered AI factories to process, refine, and manufacture intelligence from data, creating new revenue opportunities for the world's $100 trillion of industries.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"title\\\": {\\\"description\\\": \\\"title of the news\\\", \\\"title\\\": \\\"Title\\\", \\\"type\\\": \\\"string\\\"}, \\\"brief_desc\\\": {\\\"description\\\": \\\"brief descrption of the corresponding news\\\", \\\"title\\\": \\\"Brief Desc\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"title\\\", \\\"brief_desc\\\"]}\\n```\\nQuery: tell me about the company nvidia, and write a brief summary for it\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.43s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n  \\\"title\\\": \\\"NVIDIA: The Engine of Global AI Infrastructure\\\",\\n  \\\"brief_desc\\\": \\\"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n  \\\"title\\\": \\\"NVIDIA: The Engine of Global AI Infrastructure\\\",\\n  \\\"brief_desc\\\": \\\"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries.\\\"\\n}\\n```\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 70,\n",
      "                \"prompt_tokens\": 294,\n",
      "                \"total_tokens\": 364\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f04d778e-bfb3-4996-8f10-295d144628ad-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 70,\n",
      "      \"prompt_tokens\": 294,\n",
      "      \"total_tokens\": 364\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [9ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"title\": \"NVIDIA: The Engine of Global AI Infrastructure\",\n",
      "  \"brief_desc\": \"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"title\": \"NVIDIA: The Engine of Global AI Infrastructure\",\n",
      "  \"brief_desc\": \"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries.\"\n",
      "}\n",
      "<class 'dict'>\n",
      "{'title': 'NVIDIA: The Engine of Global AI Infrastructure', 'brief_desc': \"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries.\"}\n"
     ]
    }
   ],
   "source": [
    "# Debugging and logging: debug mode\n",
    "from langchain.globals import set_debug\n",
    "set_debug(True)\n",
    "\n",
    "# Try rerun the previous example to see the verbose output.\n",
    "res = websearch_chain.invoke(\"tell me about the company nvidia, and write a brief summary for it\")\n",
    "\n",
    "print_with_type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'title': 'NVIDIA: The Engine of Global AI Infrastructure', 'brief_desc': \"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries.\"}\n"
     ]
    }
   ],
   "source": [
    "set_debug(False)\n",
    "# Try rerun the previous example to see the verbose output.\n",
    "res = websearch_chain.invoke(\"tell me about the company nvidia, and write a brief summary for it\")\n",
    "\n",
    "print_with_type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Tracing with LangSmith\n",
    "\n",
    "LangSmith is a developer platform that helps you debug, test, evaluate, and monitor LLM applications. It provides:\n",
    "\n",
    "1. **Tracing**: Visualize the execution flow of your chains and agents\n",
    "2. **Debugging**: Inspect inputs, outputs, and intermediate steps\n",
    "3. **Evaluation**: Measure and compare model performance\n",
    "4. **Monitoring**: Track usage and performance in production\n",
    " \n",
    "To use LangSmith tracing:\n",
    "Set environment variables (in your .env file):\n",
    "   - `LANGCHAIN_TRACING_V2=\"true\"` to enable tracing\n",
    "   - `LANGCHAIN_API_KEY` with your LangSmith API key\n",
    "\n",
    "After running your code, you can view detailed traces at https://docs.smith.langchain.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'NVIDIA: The Engine of Global AI Infrastructure',\n",
       " 'brief_desc': \"NVIDIA is a leading technology company that powers the world's AI infrastructure. It enables companies and countries to build AI factories that process and refine data to generate intelligence, opening up new revenue opportunities across various industries estimated at $100 trillion.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@traceable # Auto-trace this function\n",
    "def pipeline(user_input: str):\n",
    "    return websearch_chain.invoke(user_input)\n",
    "pipeline(\"tell me about the nvidia companies, and write a brief summary for it\")\n",
    "# Out:  Hello there! How can I assist you today? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your task ####\n",
    "# go to the langsmith webpage and observe the traces. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 5498fe9d-37f5-4194-b8a1-b6dc8fac4880 not found for run c3764b29-c182-46e8-845a-813c8d49bc9b. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:RunnablePassthrough] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:run] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query> > chain:run] [603ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"['I am a professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University in Beijing. I have a broad research interest in distributed ...', 'Wei Xu. Professor, IIIS and CollegeAI, Tsinghua University. Verified email at tsinghua.edu.cn - Homepage · Computer Science. ArticlesCited byPublic access ...', 'Wei Xu is an assistant professor in the School of Interactive Computing at the Georgia Institute of Technology. Xu received her Ph.D. in Computer Science ...', 'List of computer science publications by Wei Xu.', 'Wei Xu is an assistant professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University. He received his Ph.D. from UC Berkeley ...', 'Associate Professor, Tsinghua University, Tsinghua University · WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\\\u202a\\\\u202a引用次数：7473 次\\\\u202c\\\\u202c - \\\\u202aComputer Science\\\\u202c', 'Tsinghua University. Assistant Professor at Institute for Interdisciplinary Information Sciences IIIS. Research Area: Distributed Systems + Machine Learning.', 'Qiang WEI, Professor | Cited by 1592 | of Tsinghua University, Beijing (TH) | Read 94 publications | Contact Qiang WEI.', 'I am a full professor and vice head of EE department. My research interests are in the areas of wireless communications, information theory, network theory, ...']\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,query>] [610ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"context\": \"['I am a professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University in Beijing. I have a broad research interest in distributed ...', 'Wei Xu. Professor, IIIS and CollegeAI, Tsinghua University. Verified email at tsinghua.edu.cn - Homepage · Computer Science. ArticlesCited byPublic access ...', 'Wei Xu is an assistant professor in the School of Interactive Computing at the Georgia Institute of Technology. Xu received her Ph.D. in Computer Science ...', 'List of computer science publications by Wei Xu.', 'Wei Xu is an assistant professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University. He received his Ph.D. from UC Berkeley ...', 'Associate Professor, Tsinghua University, Tsinghua University · WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\\\u202a\\\\u202a引用次数：7473 次\\\\u202c\\\\u202c - \\\\u202aComputer Science\\\\u202c', 'Tsinghua University. Assistant Professor at Institute for Interdisciplinary Information Sciences IIIS. Research Area: Distributed Systems + Machine Learning.', 'Qiang WEI, Professor | Cited by 1592 | of Tsinghua University, Beijing (TH) | Read 94 publications | Contact Qiang WEI.', 'I am a full professor and vice head of EE department. My research interests are in the areas of wireless communications, information theory, network theory, ...']\",\n",
      "  \"query\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"context\": \"['I am a professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University in Beijing. I have a broad research interest in distributed ...', 'Wei Xu. Professor, IIIS and CollegeAI, Tsinghua University. Verified email at tsinghua.edu.cn - Homepage · Computer Science. ArticlesCited byPublic access ...', 'Wei Xu is an assistant professor in the School of Interactive Computing at the Georgia Institute of Technology. Xu received her Ph.D. in Computer Science ...', 'List of computer science publications by Wei Xu.', 'Wei Xu is an assistant professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University. He received his Ph.D. from UC Berkeley ...', 'Associate Professor, Tsinghua University, Tsinghua University · WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\\\u202a\\\\u202a引用次数：7473 次\\\\u202c\\\\u202c - \\\\u202aComputer Science\\\\u202c', 'Tsinghua University. Assistant Professor at Institute for Interdisciplinary Information Sciences IIIS. Research Area: Distributed Systems + Machine Learning.', 'Qiang WEI, Professor | Cited by 1592 | of Tsinghua University, Beijing (TH) | Read 94 publications | Contact Qiang WEI.', 'I am a full professor and vice head of EE department. My research interests are in the areas of wireless communications, information theory, network theory, ...']\",\n",
      "  \"query\": \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query based on the following context: \\n['I am a professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University in Beijing. I have a broad research interest in distributed ...', 'Wei Xu. Professor, IIIS and CollegeAI, Tsinghua University. Verified email at tsinghua.edu.cn - Homepage · Computer Science. ArticlesCited byPublic access ...', 'Wei Xu is an assistant professor in the School of Interactive Computing at the Georgia Institute of Technology. Xu received her Ph.D. in Computer Science ...', 'List of computer science publications by Wei Xu.', 'Wei Xu is an assistant professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University. He received his Ph.D. from UC Berkeley ...', 'Associate Professor, Tsinghua University, Tsinghua University · WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\\\u202a\\\\u202a引用次数：7473 次\\\\u202c\\\\u202c - \\\\u202aComputer Science\\\\u202c', 'Tsinghua University. Assistant Professor at Institute for Interdisciplinary Information Sciences IIIS. Research Area: Distributed Systems + Machine Learning.', 'Qiang WEI, Professor | Cited by 1592 | of Tsinghua University, Beijing (TH) | Read 94 publications | Contact Qiang WEI.', 'I am a full professor and vice head of EE department. My research interests are in the areas of wireless communications, information theory, network theory, ...']\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"name\\\": {\\\"description\\\": \\\"name of the Professor\\\", \\\"title\\\": \\\"Name\\\", \\\"type\\\": \\\"string\\\"}, \\\"publications\\\": {\\\"description\\\": \\\"the string of the professor's publications, separated by comma\\\", \\\"title\\\": \\\"Publications\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"name\\\", \\\"publications\\\"]}\\n```\\nQuery: tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.98s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n  \\\"name\\\": \\\"Wei Xu\\\",\\n  \\\"publications\\\": \\\"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning, Distributed Systems + Machine Learning, ArticlesCited by 7473\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n  \\\"name\\\": \\\"Wei Xu\\\",\\n  \\\"publications\\\": \\\"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning, Distributed Systems + Machine Learning, ArticlesCited by 7473\\\"\\n}\\n```\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 56,\n",
      "                \"prompt_tokens\": 592,\n",
      "                \"total_tokens\": 648\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-076fe762-e7a6-483c-893f-b2e0a88df0b5-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 56,\n",
      "      \"prompt_tokens\": 592,\n",
      "      \"total_tokens\": 648\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [6ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"name\": \"Wei Xu\",\n",
      "  \"publications\": \"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning, Distributed Systems + Machine Learning, ArticlesCited by 7473\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.62s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"name\": \"Wei Xu\",\n",
      "  \"publications\": \"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning, Distributed Systems + Machine Learning, ArticlesCited by 7473\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# retrieve the information and fix the query results about Prof. Xu, \n",
    "# generating the correct Professor object.\n",
    "# Note that you do not have to get a perfect answer from the LLM in this lab.  \n",
    "# (if the answer is not perfect, please analyze and debug it in the next cell.)\n",
    "# @traceable\n",
    "# def xuwei(user_input: str):\n",
    "# \t\treturn professor_chain.invoke(user_input)\n",
    "# xuwei(\"tell me about professor Wei Xu including his publications.\")\n",
    "# pipeline(\"tell me about professor Wei Xu who is a tsinghua's professor including his publications.\")\n",
    "#from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "class Professor(BaseModel):\n",
    "    name: str = Field(description=\"name of the Professor\")\n",
    "    publications: str = Field(description=\"the string of the professor's publications, separated by comma\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Professor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query based on the following context: \\n{context}\\n{format_instructions}\\nQuery: {query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_model.temperature = 0\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "setup_and_retrieval = {\n",
    "        \"context\": search.run,  # passing a retriever\n",
    "        \"query\": RunnablePassthrough()\n",
    "}\n",
    "\n",
    "xuwei_chain = setup_and_retrieval | prompt | chat_model | parser\n",
    "\n",
    "@traceable\n",
    "def xuwei(user_input: str):\n",
    " \t\treturn xuwei_chain.invoke(user_input)\n",
    "set_debug(True)\n",
    "xuwei(\"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\")\n",
    "set_debug(False)\n",
    "#pipeline(\"tell me about professor Wei Xu who is a tsinghua's professor including his publications.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR TASK ####\n",
    "# analyze the answer, if the answer is not correct, write down some comments \n",
    "# about why the answer is not correct. \n",
    "# the answer is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Smarter workflow: Agents\n",
    "\n",
    "\n",
    "An AI agent is an autonomous system that perceives its environment, makes decisions, and takes actions to achieve specific goals. In the context of LLMs, an agent uses a language model as its reasoning engine to determine what actions to take and in what order, unlike chains where the sequence is predefined.\n",
    "\n",
    "LangChain provides several frameworks for building agents:\n",
    "1. **Tool integration**: LangChain allows agents to use external tools and APIs to gather information or perform actions\n",
    "2. **Agent types**: Supports various agent architectures like ReAct (Reasoning and Acting), Plan-and-Execute, and others\n",
    "3. **Memory systems**: Enables agents to maintain context across interactions (next lab)\n",
    "4. **Structured output**: Helps parse and validate agent responses\n",
    "\n",
    "For more advanced agent capabilities, LangGraph (an extension of LangChain) offers enhanced features for creating highly controllable and customizable agents with better state management and complex workflows (next lab).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Function-calling: Letter r's in straberry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following very simple example, and see if LLM can get it correct. (the correct answer is 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are two \\'r\\'s in the word \"strawberry.\"', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 40, 'total_tokens': 55}, 'model_name': 'qwen2.5-72b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': []}}, id='run-8656a966-4dfb-4dd3-bf6b-9bc67d21e806-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"how many r's are there in the word strawberry?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the AI answered incorrectly by stating there are two 'r's in the word \"strawberry\" when there are actually three 'r's (st**r**awbe**rr**y). This demonstrates a limitation of LLMs in performing simple counting tasks. Even advanced models can make these basic errors because they process text holistically rather than character-by-character like humans do. This is why tools like function calling are useful - they allow us to delegate specific tasks (like counting) to dedicated functions that can perform them accurately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[StructuredTool(name='get_letter_count', description='get_letter_count(query: str) -> int - Returns the number of a specific letter in a word. \\n    The input should be in the format: word,letter (e.g., strawberry,r)', args_schema=<class 'pydantic.v1.main.get_letter_countSchema'>, func=<function get_letter_count at 0x7f61da487760>)]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# here is an example of a tool that can be used to count the number of a specific letter in a word.\n",
    "# note that we only use a single string parameter, because the simple agent only accept tools with a single parameter.\n",
    "# to fit two parameters, we need a clear format instruction for the input.\n",
    "@tool\n",
    "def get_letter_count(query: str) -> int:\n",
    "    \"\"\"Returns the number of a specific letter in a word. \n",
    "    The input should be in the format: word,letter (e.g., strawberry,r)\"\"\"\n",
    "    word, letter = query.split(',')\n",
    "    return word.count(letter)\n",
    "\n",
    "print(get_letter_count.invoke(\"strawberry,r\"))\n",
    "\n",
    "tools = [ get_letter_count ]\n",
    "\n",
    "print(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ( \"system\", \"You are very powerful assistant who can use tools, but bad at counting letters in words.\", \n",
    "         ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # used to store the previous agent tool invocations and the corresponding tool outputs. \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/llm/llm_course_public_cxp/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"how many r's are there in the word strawberry?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"how many r's are there in the word strawberry?\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nget_letter_count: get_letter_count(query: str) -> int - Returns the number of a specific letter in a word. \\n    The input should be in the format: word,letter (e.g., strawberry,r)\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_letter_count]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: how many r's are there in the word strawberry?\\nThought:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in ConsoleCallbackHandler.on_tool_end callback: AttributeError(\"'int' object has no attribute 'strip'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [1.16s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I need to count the number of 'r' letters in the word 'strawberry'.\\nAction: get_letter_count\\nAction Input: strawberry,r\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I need to count the number of 'r' letters in the word 'strawberry'.\\nAction: get_letter_count\\nAction Input: strawberry,r\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 34,\n",
      "                \"prompt_tokens\": 205,\n",
      "                \"total_tokens\": 239\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f0ad4064-1e4f-47e3-929b-7b2a04ce5802-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 34,\n",
      "      \"prompt_tokens\": 205,\n",
      "      \"total_tokens\": 239\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I need to count the number of 'r' letters in the word 'strawberry'.\\nAction: get_letter_count\\nAction Input: strawberry,r\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:get_letter_count] Entering Tool run with input:\n",
      "\u001b[0m\"strawberry,r\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"how many r's are there in the word strawberry?\",\n",
      "  \"agent_scratchpad\": \"I need to count the number of 'r' letters in the word 'strawberry'.\\nAction: get_letter_count\\nAction Input: strawberry,r\\nObservation: 3\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nget_letter_count: get_letter_count(query: str) -> int - Returns the number of a specific letter in a word. \\n    The input should be in the format: word,letter (e.g., strawberry,r)\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_letter_count]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: how many r's are there in the word strawberry?\\nThought:I need to count the number of 'r' letters in the word 'strawberry'.\\nAction: get_letter_count\\nAction Input: strawberry,r\\nObservation: 3\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [839ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I now know the final answer\\nFinal Answer: There are 3 'r's in the word strawberry.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I now know the final answer\\nFinal Answer: There are 3 'r's in the word strawberry.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 23,\n",
      "                \"prompt_tokens\": 243,\n",
      "                \"total_tokens\": 266\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f757fbe6-48e2-4720-82e0-57ae74beba6a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 23,\n",
      "      \"prompt_tokens\": 243,\n",
      "      \"total_tokens\": 266\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [843ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I now know the final answer\\nFinal Answer: There are 3 'r's in the word strawberry.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.02s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"There are 3 'r's in the word strawberry.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "agent_chain = initialize_agent(tools, \n",
    "                               chat_model, \n",
    "                               agent=\"zero-shot-react-description\", \n",
    "                               prompt_template=prompt, \n",
    "                               verbose=False\n",
    "                               )\n",
    "\n",
    "agent_chain.invoke({\"input\": \"how many r's are there in the word strawberry?\"})\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '5', '6', '7', '8', '9']\n",
      "[StructuredTool(name='sort_arr', description='sort_arr(query: str) -> int - Return the sorted array of numbers.\\n\\t\\tThe input should be in the format: 1,2,3,4,5', args_schema=<class 'pydantic.v1.main.sort_arrSchema'>, func=<function sort_arr at 0x7f61d88d8c10>)]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"sort the array 5,8,9,1,2,3,4,5,6,7\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"sort the array 5,8,9,1,2,3,4,5,6,7\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nsort_arr: sort_arr(query: str) -> int - Return the sorted array of numbers.\\n\\t\\tThe input should be in the format: 1,2,3,4,5\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [sort_arr]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: sort the array 5,8,9,1,2,3,4,5,6,7\\nThought:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in ConsoleCallbackHandler.on_tool_end callback: AttributeError(\"'list' object has no attribute 'strip'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [1.46s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I need to use the sort_arr function to sort the array.\\nAction: sort_arr\\nAction Input: 5,8,9,1,2,3,4,5,6,7\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I need to use the sort_arr function to sort the array.\\nAction: sort_arr\\nAction Input: 5,8,9,1,2,3,4,5,6,7\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 45,\n",
      "                \"prompt_tokens\": 211,\n",
      "                \"total_tokens\": 256\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b9a185b5-f6f7-461a-a945-fedea5cc5cb7-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 45,\n",
      "      \"prompt_tokens\": 211,\n",
      "      \"total_tokens\": 256\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.47s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I need to use the sort_arr function to sort the array.\\nAction: sort_arr\\nAction Input: 5,8,9,1,2,3,4,5,6,7\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:sort_arr] Entering Tool run with input:\n",
      "\u001b[0m\"5,8,9,1,2,3,4,5,6,7\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"sort the array 5,8,9,1,2,3,4,5,6,7\",\n",
      "  \"agent_scratchpad\": \"I need to use the sort_arr function to sort the array.\\nAction: sort_arr\\nAction Input: 5,8,9,1,2,3,4,5,6,7\\nObservation: ['1', '2', '3', '4', '5', '5', '6', '7', '8', '9']\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nsort_arr: sort_arr(query: str) -> int - Return the sorted array of numbers.\\n\\t\\tThe input should be in the format: 1,2,3,4,5\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [sort_arr]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: sort the array 5,8,9,1,2,3,4,5,6,7\\nThought:I need to use the sort_arr function to sort the array.\\nAction: sort_arr\\nAction Input: 5,8,9,1,2,3,4,5,6,7\\nObservation: ['1', '2', '3', '4', '5', '5', '6', '7', '8', '9']\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [1.50s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I now know the final answer\\nFinal Answer: The sorted array is 1, 2, 3, 4, 5, 5, 6, 7, 8, 9.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I now know the final answer\\nFinal Answer: The sorted array is 1, 2, 3, 4, 5, 5, 6, 7, 8, 9.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 45,\n",
      "                \"prompt_tokens\": 287,\n",
      "                \"total_tokens\": 332\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-54085311-9e40-4565-a2e2-d81a512b8276-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 45,\n",
      "      \"prompt_tokens\": 287,\n",
      "      \"total_tokens\": 332\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I now know the final answer\\nFinal Answer: The sorted array is 1, 2, 3, 4, 5, 5, 6, 7, 8, 9.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.99s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The sorted array is 1, 2, 3, 4, 5, 5, 6, 7, 8, 9.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#### your task ####\n",
    "# implement a tool that sort an array of numbers (packed as a comma separated string)\n",
    "# then ask the agent to use the tool to sort an input array. \n",
    "@tool\n",
    "def sort_arr(query: str) -> int:\n",
    "    \"\"\"Return the sorted array of numbers.\n",
    "\t\tThe input should be in the format: 1,2,3,4,5\"\"\"\n",
    "    arr = query.split(',')\n",
    "    arr.sort()\n",
    "    return arr\n",
    "\n",
    "print(sort_arr.invoke(\"5,8,9,1,2,3,4,5,6,7\"))\n",
    "\n",
    "tools = [ sort_arr ]\n",
    "\n",
    "print(tools)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ( \"system\", \"You are very powerful assistant who can use tools, but bad at sorting array.\", \n",
    "         ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # used to store the previous agent tool invocations and the corresponding tool outputs. \n",
    "    ]\n",
    ")\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "agent_chain = initialize_agent(tools, \n",
    "                               chat_model, \n",
    "                               agent=\"zero-shot-react-description\", \n",
    "                               prompt_template=prompt, \n",
    "                               verbose=False\n",
    "                               )\n",
    "\n",
    "agent_chain.invoke({\"input\":  \"sort the array 5,8,9,1,2,3,4,5,6,7\"})\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create an auto-web-search AI Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the following example about the built-in web-search tool and understand the code. \n",
    "\n",
    "\n",
    "from langchain.agents import load_tools \n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=News)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, helping the users search the web and write summary for the user's interested topic: {keyword}\",\n",
    "        ),\n",
    "        (\"user\", \"{keyword}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # used to store the previous agent tool invocations and the corresponding tool outputs. \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "tools = [load_tools([\"serpapi\"], chat_model)[0]]\n",
    "\n",
    "agent_chain = initialize_agent(tools, chat_model, agent=\"zero-shot-react-description\", prompt_template=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the latest news from Tsinghua University within the last week.\n",
      "Action: Search\n",
      "Action Input: \"Tsinghua University news last week\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[' entity_type: related_questions.', '\\u200bResearch teams from Tsinghua University and Beijing Tongren Hospital discover new immunological mechanisms driving the recurrence of chronic rhinosinusitis...', 'Vietnamese Prime Minister Pham Minh Chinh meets with Secretary of the CPC Tsinghua University Committee Qiu Yong and witnesses signing of MoUs with ...', 'The latest news, analysis and opinion on Tsinghua University. In-depth analysis, industry insights and expert opinion.', 'LATEST NEWS · Mar25. Spring in Tsinghua · Mar18. Exhibition of Indonesian modern, contemporary art opens in Beijing · Mar17. Tsinghua hosts job fair for 2021 ...', 'LATEST NEWS · May26. Pritzker-Tsinghua Fellowship Program Inaugurated · May20. Pennsylvania State University President Visits Tsinghua · May16. Tsinghua Ranks ...', 'LATEST NEWS · May06. Premier Wen Jiabao, Delegation Visit Students on Youth Day · May06. Vice President Hu meets with Hong Kong, Macao and Taiwan Students · May06.', \"In a recent year, 41 percent of the university's non-Chinese students were undergraduates, 29 percent were pursuing master's degrees, 9 percent were doctoral ...\", 'HEADLINES · Multi-stakeholders from 6 Continents Co-initiate the Global Youth Climate Week · HEADLINES · The 2nd World Health Forum Opens · HEADLINES · \\u200bWhere ...', 'UW and Tsinghua University create groundbreaking partnership with launch of the Global Innovation Exchange. UW News staff ...', 'This is the end of the student takeover. It was my pleasure showing you guys the Chinese New Year celebration here in Malaysia.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found several pieces of news from Tsinghua University within the last week. I will summarize the most relevant ones.\n",
      "Final Answer: Within the last week, notable news from Tsinghua University includes:\n",
      "1. Research teams from Tsinghua University and Beijing Tongren Hospital have discovered new immunological mechanisms driving the recurrence of chronic rhinosinusitis.\n",
      "2. Vietnamese Prime Minister Pham Minh Chinh met with Secretary of the CPC Tsinghua University Committee Qiu Yong and witnessed the signing of Memorandums of Understanding (MoUs) with the university.\n",
      "3. Tsinghua University hosted a job fair for the year 2021, indicating ongoing efforts to support student employment and career development.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me the news from tsinghua university within last week?',\n",
       " 'output': 'Within the last week, notable news from Tsinghua University includes:\\n1. Research teams from Tsinghua University and Beijing Tongren Hospital have discovered new immunological mechanisms driving the recurrence of chronic rhinosinusitis.\\n2. Vietnamese Prime Minister Pham Minh Chinh met with Secretary of the CPC Tsinghua University Committee Qiu Yong and witnessed the signing of Memorandums of Understanding (MoUs) with the university.\\n3. Tsinghua University hosted a job fair for the year 2021, indicating ongoing efforts to support student employment and career development.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"tell me the news from tsinghua university within last week?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for information about Professor Wei Xu from Tsinghua University and find at least three of his publications.\n",
      "Action: Search\n",
      "Action Input: \"Professor Wei Xu Tsinghua University publications\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Wei Xu. Professor, IIIS and CollegeAI, Tsinghua University. Verified email at tsinghua.edu.cn - Homepage · Computer Science. ArticlesCited byPublic access ...', '(For a full list of publications, please see my Google Scholar Page.) Training Job Placement in Clusters with Statistical In-Network Aggregation. Bohan Zhao, ...', 'Wei XU | Cited by 722 | of Tsinghua University, Beijing (TH) | Read 29 publications | Contact Wei XU.', 'Publication Topics. Convolutional Layers,Convolutional Neural Network,Deep Learning,Deep Neural Network,Dice Similarity Coefficient,Feature Maps,Fully ...', 'List of computer science publications by Wei Xu.', \"Wei Xu's 6 research works with 114 citations, including: Multi-object events recognition from video sequences using extended finite state machine.\", \"Beijing Pioneer in Teacher's Ethics. 2018. Tsinghua University Lab Design Award (3rd class). 2018. Tsinghua University Excellent Performance Employee Award.\", 'View the Special Programme for Research & Training in Tropical Diseases profile of Jian-wei Xu. Including their publications and grants.', 'Xu Wei, research professor, received his PhD degree from University of Chinese Academy of Sciences in 2016. · Working Experience · 2020.3-present, Agricultural ...', 'Xu received her Ph.D. in Computer Science from New York University, and her B.S. and M.S. from Tsinghua University. Her research interests are in natural ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results provide some information about Professor Wei Xu, but the specific publications are not clearly listed. I need to refine the search to find more detailed information about his publications.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University Google Scholar\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[' entity_type: related_questions.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202a引用次数：7473 次\\u202c\\u202c - \\u202aComputer Science\\u202c', 'I worked for Google for 2.5 years as a software engineer before joining Tsinghua. My Google Scholar Page tracks more recent publications, and may be more up-to- ...', 'Tsinghua University - \\u202a\\u202aCited by 4647\\u202c\\u202c - \\u202ahigh performance computing\\u202c - \\u202ascientific computing\\u202c - \\u202aparallel I/O\\u202c - \\u202aclimate system modeling\\u202c - \\u202auncertainty\\u202c ...', 'Xu received her Ph.D. in Computer Science from New York University, and her B.S. and M.S. from Tsinghua University. Her research interests are in natural ...', 'I am a Ph.D. student in the Department of Computer Science and Technology at Tsinghua University, advised by Professor Zhiyuan Liu.', 'Wei Fu. Pronouns: he/him. PhD student, Institute for Interdisciplinary Information Sciences, Tsinghua University, Tsinghua University. Joined May 2021 ...', 'Google Scholar. Suggest URL. Career & Education History. Associate Professor. Tsinghua University, Tsinghua University (tsinghua.edu.cn). 2019 – Present.', 'Extrachromosomal DNA (ecDNA) presents a promising target for cancer therapy; however, its spatial-temporal diversity and influence on tumor ...', 'Beijing: Tsinghua University Press, 2005. Google Scholar. Wang Shu, Yang Yujie, Hu Fuping et. Theory and application of wireless sensor ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results indicate that Professor Wei Xu has a Google Scholar page, which is likely to contain a comprehensive list of his publications. I will visit his Google Scholar page to find the specific publications.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University Google Scholar profile\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202a引用次数：7473 次\\u202c\\u202c - \\u202aComputer Science\\u202c', 'I worked for Google for 2.5 years as a software engineer before joining Tsinghua. My Google Scholar Page tracks more recent publications, and may be more up-to- ...', 'Tsinghua University - \\u202a\\u202aCited by 4647\\u202c\\u202c - \\u202ahigh performance computing\\u202c - \\u202ascientific computing\\u202c - \\u202aparallel I/O\\u202c - \\u202aclimate system modeling\\u202c - \\u202auncertainty\\u202c ...', 'Xu received her Ph.D. in Computer Science from New York University, and her B.S. and M.S. from Tsinghua University. Her research interests are in natural ...', 'List of computer science publications by Wei Xu.', 'I am a Ph.D. student in the Department of Computer Science and Technology at Tsinghua University, advised by Professor Zhiyuan Liu.', 'Wei Fu. Pronouns: he/him. PhD student, Institute for Interdisciplinary Information Sciences, Tsinghua University, Tsinghua University. Joined May 2021 ...', 'Google Scholar. Suggest URL. Career & Education History. Associate Professor. Tsinghua University, Tsinghua University (tsinghua.edu.cn). 2019 – Present.', 'Apr 2024 I passed the PhD qualification exam (preliminary+oral) at IIIS, Tsinghua! Dec 2023 I recieved the overall execellence scholarship at Tsinghua! Apr 2023 ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results still do not provide a direct link to Professor Wei Xu's Google Scholar profile. I will attempt to find the profile directly by searching for \"Wei Xu Tsinghua University\" and looking for a link to his Google Scholar page.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University Google Scholar profile link\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[' entity_type: related_questions.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202a引用次数：7473 次\\u202c\\u202c - \\u202aComputer Science\\u202c', 'I worked for Google for 2.5 years as a software engineer before joining Tsinghua. My Google Scholar Page tracks more recent publications, and may be more up-to- ...', 'List of computer science publications by Wei Xu.', 'Revisiting some common practices in cooperative multi-agent reinforcement learning W Fu, C Yu, Z Xu, J Yang, Y Wu arXiv preprint arXiv:2206.07505, 2022', 'Wei Fu. Pronouns: he/him. PhD student, Institute for Interdisciplinary Information Sciences, Tsinghua University, Tsinghua University. Joined May 2021 ...', '-. Education. Tsinghua University Graphic. Tsinghua University. Publications. See my publications at Google Scholar https://goo.gl/qxAM3N. -. See publication ...', 'Xiuwei Xu. PhD ... Personal Links. Homepage · Google Scholar · DBLP. Suggest URL. Career & Education History. PhD student. Tsinghua University, Tsinghua ...', 'Wang is also a named inventor on 8 US patents. Google Scholar. Professional and Education Experiences: The University of Chicago, Assistant Professor, Sep. 2018 ...', 'Tenured Associate Professor (02/2024 - present), The Department of Electronic Engineering, Tsinghua University, Beijing, China · Tenure-track Associate Professor ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results include a link to Professor Wei Xu's Google Scholar profile. I will use this link to find the specific publications.\n",
      "Action: Search\n",
      "Action Input: \"https://goo.gl/qxAM3N\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['-. -. -. Education. Tsinghua University Graphic. Tsinghua University. Publications. See my publications at Google Scholar https://goo.gl/qxAM3N. -. See ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe link provided in the search results is a shortened URL. I need to directly access this URL to find the specific publications by Professor Wei Xu.\n",
      "Action: Search\n",
      "Action Input: \"https://goo.gl/qxAM3N\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['-. -. -. Education. Tsinghua University Graphic. Tsinghua University. Publications. See my publications at Google Scholar https://goo.gl/qxAM3N. -. See ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there was an issue with the shortened URL. I will try to find the direct Google Scholar profile link again.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University Google Scholar profile direct link\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[' entity_type: related_questions.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202a引用次数：7473 次\\u202c\\u202c - \\u202aComputer Science\\u202c', 'I worked for Google for 2.5 years as a software engineer before joining Tsinghua. My Google Scholar Page tracks more recent publications, and may be more up-to- ...', 'PhD, University of Hong Kong - \\u202a\\u202aCited by 3039\\u202c\\u202c - \\u202aSensor fusion\\u202c ... Fast-livo: Fast and tightly-coupled sparse-direct lidar-inertial-visual odometry.', 'Zongyu Lin. PhD student, Computer Science, University of California, Los Angeles. Joined November 2021. Names. Zongyu Lin (Preferred). Suggest Name. Emails.', 'These findings indicate that the miR-183C drives Th17 pathogenicity in autoimmune diseases via inhibition of Foxo1 and present promising therapeutic targets.', 'Tenured Associate Professor (02/2024 - present), The Department of Electronic Engineering, Tsinghua University, Beijing, China · Tenure-track Associate Professor ...', 'A systematic review of design, properties, applications, challenges, and 3D Printing of materials and cellular metamaterials', 'List of computer science publications by Wei Xu.', \"Hongwei Fang currently works at the Department of Hydraulic Engineering, Tsinghua University. Their current project is 'sediment transport and its impact on ...\"]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results still do not provide a direct link to Professor Wei Xu's Google Scholar profile. I will attempt to find the profile by searching for \"Wei Xu Tsinghua University\" and looking for a personal or professional page that might contain the link.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University personal page\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['I am a professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University in Beijing. I have a broad research interest in distributed ...', 'Wei Xu, Vice Dean, Professor, Institute for Interdisciplinary Information Sciences, Tsinghua University. Office: FIT-4-6005, Tsinghua University, Beijing, ...', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'Experience · M.S. degree, Cyberspace Security, Tsinghua University. 2021 - Now · B.S. degree, Software Engineering, Shandong University. 2013-2017 ...', 'Xu received her Ph.D. in Computer Science from New York University, and her B.S. and M.S. from Tsinghua University. Her research interests are in natural ...', 'Wei Xu. Associate Professor, Tsinghua University, Tsinghua University. Joined February 2020. Names. Wei Xu (Preferred). Suggest Name. Emails.', 'He is an Assistant Professor with the Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China. He is the Director of Open ...', 'Fellowship in College of Engineering. Pennsylvania State University. Aug 2007. Excellent Thesis of Bachelor. Tsinghua University. Jun 2005. Organizations. IEEE, ...', 'Wei Xu is an assistant professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University. He received his Ph.D. from UC Berkeley ...', 'Wei XU | Cited by 722 | of Tsinghua University, Beijing (TH) | Read 29 publications | Contact Wei XU. ... 160+ million publication pages; 2.3+ billion citations.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results include a personal page for Professor Wei Xu, which should contain a link to his Google Scholar profile. I will visit this page to find the link.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University personal page link to Google Scholar\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[' entity_type: related_questions.', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'I am a professor at the Institute for Interdisciplinary Information Sciences of Tsinghua University in Beijing. ... My Google Scholar Page tracks more recent ...', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202a引用次数：7473 次\\u202c\\u202c - \\u202aComputer Science\\u202c', 'List of computer science publications by Wei Xu.', 'Horizon Robotics - \\u202a\\u202aCited by 33008\\u202c\\u202c - \\u202aartificial intelligence\\u202c - \\u202adeep learning\\u202c - \\u202aNLP\\u202c - \\u202acomputer vision\\u202c - \\u202areinforcement learning\\u202c', '-. Education. Tsinghua University Graphic. Tsinghua University. Publications. See my publications at Google Scholar https://goo.gl/qxAM3N. -. See publication ...', 'The links to all actual bibliographies of persons of the same or a similar name can be found below. Any publication listed on this page has not been assigned to ...', 'Co-authors ; Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020.', 'July. 2024: Welcome our two new undergrad visiting students, Wei Xu from Tsinghua University and Muyang Zhou from University of Science and Techonology of China ...', 'I received B.E. degree from Tsinghua University in 2014. More about me: Google scholar, Github, Resume (very outdated),. Email: zhenheny at gmail.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results include a direct link to Professor Wei Xu's Google Scholar profile. I will use this link to find the specific publications.\n",
      "Action: Search\n",
      "Action Input: \"https://scholar.google.com/citations?user=QxAM3NAAAAAJ&hl=en\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[' entity_type: related_questions.', 'Google Scholar Citations lets you track citations to your publications over time.', 'Google Scholar provides a simple way to broadly search for scholarly literature. Search across a wide variety of disciplines and sources: articles, theses, ...', 'No information is available for this page.', 'No information is available for this page.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there was an issue with the direct link to Professor Wei Xu's Google Scholar profile. I will try to find the publications by searching for his name and affiliation on Google Scholar directly.\n",
      "Action: Search\n",
      "Action Input: \"Wei Xu Tsinghua University publications on Google Scholar\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202aCited by 7449\\u202c\\u202c - \\u202aComputer Science\\u202c', 'Professor, IIIS and CollegeAI, Tsinghua University - \\u202a\\u202a引用次数：7473 次\\u202c\\u202c - \\u202aComputer Science\\u202c', 'I worked for Google for 2.5 years as a software engineer before joining Tsinghua. My Google Scholar Page tracks more recent publications, and may be more up-to- ...', 'Tsinghua University - \\u202a\\u202aCited by 4647\\u202c\\u202c - \\u202ahigh performance computing\\u202c - \\u202ascientific computing\\u202c - \\u202aparallel I/O\\u202c - \\u202aclimate system modeling\\u202c - \\u202auncertainty\\u202c ...', 'Xu received her Ph.D. in Computer Science from New York University, and her B.S. and M.S. from Tsinghua University. Her research interests are in natural ...', 'List of computer science publications by Wei Xu.', 'I am a research assistant professor in the Department of Computer Science and Technology at Tsinghua University. My research interests include natural language ...', 'PhD student, Institute for Interdisciplinary Information Sciences, Tsinghua University, Tsinghua University (mails.tsinghua.edu.cn) 2021 – 2026', 'This is just a disambiguation page, and is not intended to be the bibliography of an actual person. The links to all actual bibliographies of persons of the ...', 'PhD student, IIIS, Tsinghua University ; On Designing Effective RL Reward at Training Time for LLM Reasoning ·, Shusheng Xu, Wenjie Ye, Weilin Liu, Chuyi He, Wei ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results still do not provide a direct link to the publications. However, I can see some of the publications listed in the search results. I will list the ones that are clearly identified.\n",
      "Thought: I now know the final answer\n",
      "Final Answer: Professor Wei Xu is a professor at the Institute for Interdisciplinary Information Sciences (IIIS) and CollegeAI at Tsinghua University. Here are three of his publications:\n",
      "\n",
      "1. **\"Training Job Placement in Clusters with Statistical In-Network Aggregation\"** - Co-authors: Bohan Zhao, et al.\n",
      "2. **\"Revisiting some common practices in cooperative multi-agent reinforcement learning\"** - Co-authors: Wei Fu, Chao Yu, Zhiyuan Xu, Jian Yang, Yu Wu.\n",
      "3. **\"On Designing Effective RL Reward at Training Time for LLM Reasoning\"** - Co-authors: Shusheng Xu, Wenjie Ye, Weilin Liu, Chuyi He, Wei Xu.\n",
      "\n",
      "For a more comprehensive list, you can visit his Google Scholar profile directly.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\",\n",
       " 'output': 'Professor Wei Xu is a professor at the Institute for Interdisciplinary Information Sciences (IIIS) and CollegeAI at Tsinghua University. Here are three of his publications:\\n\\n1. **\"Training Job Placement in Clusters with Statistical In-Network Aggregation\"** - Co-authors: Bohan Zhao, et al.\\n2. **\"Revisiting some common practices in cooperative multi-agent reinforcement learning\"** - Co-authors: Wei Fu, Chao Yu, Zhiyuan Xu, Jian Yang, Yu Wu.\\n3. **\"On Designing Effective RL Reward at Training Time for LLM Reasoning\"** - Co-authors: Shusheng Xu, Wenjie Ye, Weilin Liu, Chuyi He, Wei Xu.\\n\\nFor a more comprehensive list, you can visit his Google Scholar profile directly.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# use the web search tool to find out about \n",
    "# prof. wei xu and his publication list.  \n",
    "# Compare the results with the previous implementation. is it better or worse?\n",
    "agent_chain.invoke(\"tell me about professor Wei Xu who is a tsinghua's professor. Please list at least 3 of his publications.\")\n",
    "# the result is the same as the previous implementation\n",
    "# only some publications are right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Use one of the built-in tool for langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Tell xu wei sth about google ai-jobs and ai-trends.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Tell xu wei sth about google ai-jobs and ai-trends.\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\ngoogle_trends: A wrapper around Google Trends Search. Useful for when you need to get information aboutgoogle search trends from Google TrendsInput should be a search query.\\ngoogle_jobs: A wrapper around Google Jobs Search. Useful for when you need to get information aboutgoogle search Jobs from Google JobsInput should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [google_trends, google_jobs]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Tell xu wei sth about google ai-jobs and ai-trends.\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [1.26s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 33,\n",
      "                \"prompt_tokens\": 232,\n",
      "                \"total_tokens\": 265\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1fda2d41-70b0-4e76-bcc7-ad9c6adafe8e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 33,\n",
      "      \"prompt_tokens\": 232,\n",
      "      \"total_tokens\": 265\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.27s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:google_jobs] Entering Tool run with input:\n",
      "\u001b[0m\"AI jobs\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:google_jobs] [1.01s] Exiting Tool run with output:\n",
      "\u001b[0m\"_______________________________________________\n",
      "Job Title: AI Content Reviewer\n",
      "Company Name: Outlier\n",
      "Location: Mason, OH\n",
      "Description: Elevate AI Performance with Your Writing Expertise Outlier helps the world's most innovative companies improve their AI models by providing human feedback. We're seeking experienced English writers who want to make a meaningful impact in the rapidly evolving AI industry. About the Opportunity: Join Outlier as a talented writer with English fluency to help train and refine generative AI models Enjoy a flexible, remote freelance position that adapts to your schedule - work when it's most convenient for you Contribute directly to improving AI systems used by leading companies worldwide Your Role in Enhancing AI Quality: Evaluate and rank AI-generated responses, applying your expert judgment to identify high-quality outputs Craft and refine prompts that help AI systems better understand human intent and context Review AI workflows to identify areas for improvement in content generation Conduct research and fact-checking to ensure AI outputs maintain high standards of accuracy Assess the factuality, relevance, and coherence of AI-generated content What Makes You a Great Fit: Experience as a professional writer or editor Education in a writing-related discipline (associate degree or higher from an accredited institution) Exceptional English language skills with strong command of grammar, spelling, and writing style Advanced critical thinking and reasoning abilities to evaluate content quality Meticulous attention to detail and the ability to clearly articulate the strengths and weaknesses of text Interest in contributing to the advancement of AI technology Compensation: Current pay rates for core project work by English writing experts in the US range from $15 to $35 USD per hour Rates vary based on expertise, skills assessment, location, project needs, and other factors. Pay could fluctuate over time based on project availability. Additional incentive payments available on certain projects PLEASE NOTE: We collect, retain and use personal data for our professional business purposes, including notifying you of opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants’ needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with the\n",
      "\n",
      "Outlier Privacy Policy and our internal policies and programs designed to protect personal data. This is a 1099 contract opportunity on the Outlier.ai platform. Because this is a freelance opportunity, we do not offer internships, sponsorship, or employment. You must be authorized to work in your country of residence. If you are an international student, you may be able to sign up for Outlier if you are on a visa. You should contact your tax and/or immigration advisor with specific questions regarding your circumstances.\n",
      "_______________________________________________\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Tell xu wei sth about google ai-jobs and ai-trends.\",\n",
      "  \"agent_scratchpad\": \"I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\\nObservation: \\n_______________________________________________\\nJob Title: AI Content Reviewer\\nCompany Name: Outlier\\nLocation: Mason, OH\\nDescription: Elevate AI Performance with Your Writing Expertise Outlier helps the world's most innovative companies improve their AI models by providing human feedback. We're seeking experienced English writers who want to make a meaningful impact in the rapidly evolving AI industry. About the Opportunity: Join Outlier as a talented writer with English fluency to help train and refine generative AI models Enjoy a flexible, remote freelance position that adapts to your schedule - work when it's most convenient for you Contribute directly to improving AI systems used by leading companies worldwide Your Role in Enhancing AI Quality: Evaluate and rank AI-generated responses, applying your expert judgment to identify high-quality outputs Craft and refine prompts that help AI systems better understand human intent and context Review AI workflows to identify areas for improvement in content generation Conduct research and fact-checking to ensure AI outputs maintain high standards of accuracy Assess the factuality, relevance, and coherence of AI-generated content What Makes You a Great Fit: Experience as a professional writer or editor Education in a writing-related discipline (associate degree or higher from an accredited institution) Exceptional English language skills with strong command of grammar, spelling, and writing style Advanced critical thinking and reasoning abilities to evaluate content quality Meticulous attention to detail and the ability to clearly articulate the strengths and weaknesses of text Interest in contributing to the advancement of AI technology Compensation: Current pay rates for core project work by English writing experts in the US range from $15 to $35 USD per hour Rates vary based on expertise, skills assessment, location, project needs, and other factors. Pay could fluctuate over time based on project availability. Additional incentive payments available on certain projects PLEASE NOTE: We collect, retain and use personal data for our professional business purposes, including notifying you of opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants’ needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with the\\n\\nOutlier Privacy Policy and our internal policies and programs designed to protect personal data. This is a 1099 contract opportunity on the Outlier.ai platform. Because this is a freelance opportunity, we do not offer internships, sponsorship, or employment. You must be authorized to work in your country of residence. If you are an international student, you may be able to sign up for Outlier if you are on a visa. You should contact your tax and/or immigration advisor with specific questions regarding your circumstances.\\n_______________________________________________\\n\\n\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\ngoogle_trends: A wrapper around Google Trends Search. Useful for when you need to get information aboutgoogle search trends from Google TrendsInput should be a search query.\\ngoogle_jobs: A wrapper around Google Jobs Search. Useful for when you need to get information aboutgoogle search Jobs from Google JobsInput should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [google_trends, google_jobs]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Tell xu wei sth about google ai-jobs and ai-trends.\\nThought:I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\\nObservation: \\n_______________________________________________\\nJob Title: AI Content Reviewer\\nCompany Name: Outlier\\nLocation: Mason, OH\\nDescription: Elevate AI Performance with Your Writing Expertise Outlier helps the world's most innovative companies improve their AI models by providing human feedback. We're seeking experienced English writers who want to make a meaningful impact in the rapidly evolving AI industry. About the Opportunity: Join Outlier as a talented writer with English fluency to help train and refine generative AI models Enjoy a flexible, remote freelance position that adapts to your schedule - work when it's most convenient for you Contribute directly to improving AI systems used by leading companies worldwide Your Role in Enhancing AI Quality: Evaluate and rank AI-generated responses, applying your expert judgment to identify high-quality outputs Craft and refine prompts that help AI systems better understand human intent and context Review AI workflows to identify areas for improvement in content generation Conduct research and fact-checking to ensure AI outputs maintain high standards of accuracy Assess the factuality, relevance, and coherence of AI-generated content What Makes You a Great Fit: Experience as a professional writer or editor Education in a writing-related discipline (associate degree or higher from an accredited institution) Exceptional English language skills with strong command of grammar, spelling, and writing style Advanced critical thinking and reasoning abilities to evaluate content quality Meticulous attention to detail and the ability to clearly articulate the strengths and weaknesses of text Interest in contributing to the advancement of AI technology Compensation: Current pay rates for core project work by English writing experts in the US range from $15 to $35 USD per hour Rates vary based on expertise, skills assessment, location, project needs, and other factors. Pay could fluctuate over time based on project availability. Additional incentive payments available on certain projects PLEASE NOTE: We collect, retain and use personal data for our professional business purposes, including notifying you of opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants’ needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with the\\n\\nOutlier Privacy Policy and our internal policies and programs designed to protect personal data. This is a 1099 contract opportunity on the Outlier.ai platform. Because this is a freelance opportunity, we do not offer internships, sponsorship, or employment. You must be authorized to work in your country of residence. If you are an international student, you may be able to sign up for Outlier if you are on a visa. You should contact your tax and/or immigration advisor with specific questions regarding your circumstances.\\n_______________________________________________\\n\\n\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [1.53s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I have gathered information on an AI job, but to provide a more comprehensive answer, I should also look into AI trends.\\nAction: google_trends\\nAction Input: AI trends\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I have gathered information on an AI job, but to provide a more comprehensive answer, I should also look into AI trends.\\nAction: google_trends\\nAction Input: AI trends\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 40,\n",
      "                \"prompt_tokens\": 812,\n",
      "                \"total_tokens\": 852\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-27fc6391-71bf-40ff-a5ae-6180c7f0f337-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 40,\n",
      "      \"prompt_tokens\": 812,\n",
      "      \"total_tokens\": 852\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [1.53s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I have gathered information on an AI job, but to provide a more comprehensive answer, I should also look into AI trends.\\nAction: google_trends\\nAction Input: AI trends\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:google_trends] Entering Tool run with input:\n",
      "\u001b[0m\"AI trends\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:google_trends] [1.26s] Exiting Tool run with output:\n",
      "\u001b[0m\"Query: AI trends\n",
      "Date From: Mar 10, 2024\n",
      "Date To: Mar 15, 2025\n",
      "Min Value: 37\n",
      "Max Value: 100\n",
      "Average Value: 52.735849056603776\n",
      "Percent Change: 65.21739130434783%\n",
      "Trend values: 46, 44, 40, 40, 47, 46, 44, 42, 37, 42, 39, 41, 42, 42, 43, 46, 40, 48, 45, 42, 44, 45, 47, 47, 49, 49, 48, 51, 53, 48, 48, 50, 51, 50, 47, 54, 55, 53, 61, 59, 50, 43, 54, 65, 62, 63, 90, 79, 83, 100, 90, 75, 76\n",
      "Rising Related Queries: deepseek, deepseek ai, agentic ai, kling ai, ai humanizer free, how ai is transforming industries, latest programming languages 2025, understanding apis and their uses, cybersecurity basics for individuals and businesses, 5g smartphones, top skills to learn for career growth, the power of journaling for mental clarity, how to build better habits using science, ai powered home devices, premium audio systems, napkin ai, how to set and achieve smart goals, how blockchain works explained, introduction to cloud computing for beginners, ai trends 2025, ai trends 2024\n",
      "Top Related Queries: trends in ai, google ai, google trends, ai trends 2024, what is ai, ai trends 2025, technology trends, new ai trends, current trends, ai tools, generative ai trends, chatgpt ai, generative ai, digital trends, ai generator, current trends in ai, video ai, ai news, ai trend, artificial intelligence, deepseek, deepseek ai, agentic ai, kling ai, ai humanizer free\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Tell xu wei sth about google ai-jobs and ai-trends.\",\n",
      "  \"agent_scratchpad\": \"I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\\nObservation: \\n_______________________________________________\\nJob Title: AI Content Reviewer\\nCompany Name: Outlier\\nLocation: Mason, OH\\nDescription: Elevate AI Performance with Your Writing Expertise Outlier helps the world's most innovative companies improve their AI models by providing human feedback. We're seeking experienced English writers who want to make a meaningful impact in the rapidly evolving AI industry. About the Opportunity: Join Outlier as a talented writer with English fluency to help train and refine generative AI models Enjoy a flexible, remote freelance position that adapts to your schedule - work when it's most convenient for you Contribute directly to improving AI systems used by leading companies worldwide Your Role in Enhancing AI Quality: Evaluate and rank AI-generated responses, applying your expert judgment to identify high-quality outputs Craft and refine prompts that help AI systems better understand human intent and context Review AI workflows to identify areas for improvement in content generation Conduct research and fact-checking to ensure AI outputs maintain high standards of accuracy Assess the factuality, relevance, and coherence of AI-generated content What Makes You a Great Fit: Experience as a professional writer or editor Education in a writing-related discipline (associate degree or higher from an accredited institution) Exceptional English language skills with strong command of grammar, spelling, and writing style Advanced critical thinking and reasoning abilities to evaluate content quality Meticulous attention to detail and the ability to clearly articulate the strengths and weaknesses of text Interest in contributing to the advancement of AI technology Compensation: Current pay rates for core project work by English writing experts in the US range from $15 to $35 USD per hour Rates vary based on expertise, skills assessment, location, project needs, and other factors. Pay could fluctuate over time based on project availability. Additional incentive payments available on certain projects PLEASE NOTE: We collect, retain and use personal data for our professional business purposes, including notifying you of opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants’ needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with the\\n\\nOutlier Privacy Policy and our internal policies and programs designed to protect personal data. This is a 1099 contract opportunity on the Outlier.ai platform. Because this is a freelance opportunity, we do not offer internships, sponsorship, or employment. You must be authorized to work in your country of residence. If you are an international student, you may be able to sign up for Outlier if you are on a visa. You should contact your tax and/or immigration advisor with specific questions regarding your circumstances.\\n_______________________________________________\\n\\n\\nThought:I have gathered information on an AI job, but to provide a more comprehensive answer, I should also look into AI trends.\\nAction: google_trends\\nAction Input: AI trends\\nObservation: Query: AI trends\\nDate From: Mar 10, 2024\\nDate To: Mar 15, 2025\\nMin Value: 37\\nMax Value: 100\\nAverage Value: 52.735849056603776\\nPercent Change: 65.21739130434783%\\nTrend values: 46, 44, 40, 40, 47, 46, 44, 42, 37, 42, 39, 41, 42, 42, 43, 46, 40, 48, 45, 42, 44, 45, 47, 47, 49, 49, 48, 51, 53, 48, 48, 50, 51, 50, 47, 54, 55, 53, 61, 59, 50, 43, 54, 65, 62, 63, 90, 79, 83, 100, 90, 75, 76\\nRising Related Queries: deepseek, deepseek ai, agentic ai, kling ai, ai humanizer free, how ai is transforming industries, latest programming languages 2025, understanding apis and their uses, cybersecurity basics for individuals and businesses, 5g smartphones, top skills to learn for career growth, the power of journaling for mental clarity, how to build better habits using science, ai powered home devices, premium audio systems, napkin ai, how to set and achieve smart goals, how blockchain works explained, introduction to cloud computing for beginners, ai trends 2025, ai trends 2024\\nTop Related Queries: trends in ai, google ai, google trends, ai trends 2024, what is ai, ai trends 2025, technology trends, new ai trends, current trends, ai tools, generative ai trends, chatgpt ai, generative ai, digital trends, ai generator, current trends in ai, video ai, ai news, ai trend, artificial intelligence, deepseek, deepseek ai, agentic ai, kling ai, ai humanizer free\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\ngoogle_trends: A wrapper around Google Trends Search. Useful for when you need to get information aboutgoogle search trends from Google TrendsInput should be a search query.\\ngoogle_jobs: A wrapper around Google Jobs Search. Useful for when you need to get information aboutgoogle search Jobs from Google JobsInput should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [google_trends, google_jobs]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Tell xu wei sth about google ai-jobs and ai-trends.\\nThought:I need to gather information on AI jobs and AI trends to provide Xu Wei with relevant details.\\nAction: google_jobs\\nAction Input: AI jobs\\nObservation: \\n_______________________________________________\\nJob Title: AI Content Reviewer\\nCompany Name: Outlier\\nLocation: Mason, OH\\nDescription: Elevate AI Performance with Your Writing Expertise Outlier helps the world's most innovative companies improve their AI models by providing human feedback. We're seeking experienced English writers who want to make a meaningful impact in the rapidly evolving AI industry. About the Opportunity: Join Outlier as a talented writer with English fluency to help train and refine generative AI models Enjoy a flexible, remote freelance position that adapts to your schedule - work when it's most convenient for you Contribute directly to improving AI systems used by leading companies worldwide Your Role in Enhancing AI Quality: Evaluate and rank AI-generated responses, applying your expert judgment to identify high-quality outputs Craft and refine prompts that help AI systems better understand human intent and context Review AI workflows to identify areas for improvement in content generation Conduct research and fact-checking to ensure AI outputs maintain high standards of accuracy Assess the factuality, relevance, and coherence of AI-generated content What Makes You a Great Fit: Experience as a professional writer or editor Education in a writing-related discipline (associate degree or higher from an accredited institution) Exceptional English language skills with strong command of grammar, spelling, and writing style Advanced critical thinking and reasoning abilities to evaluate content quality Meticulous attention to detail and the ability to clearly articulate the strengths and weaknesses of text Interest in contributing to the advancement of AI technology Compensation: Current pay rates for core project work by English writing experts in the US range from $15 to $35 USD per hour Rates vary based on expertise, skills assessment, location, project needs, and other factors. Pay could fluctuate over time based on project availability. Additional incentive payments available on certain projects PLEASE NOTE: We collect, retain and use personal data for our professional business purposes, including notifying you of opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants’ needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with the\\n\\nOutlier Privacy Policy and our internal policies and programs designed to protect personal data. This is a 1099 contract opportunity on the Outlier.ai platform. Because this is a freelance opportunity, we do not offer internships, sponsorship, or employment. You must be authorized to work in your country of residence. If you are an international student, you may be able to sign up for Outlier if you are on a visa. You should contact your tax and/or immigration advisor with specific questions regarding your circumstances.\\n_______________________________________________\\n\\n\\nThought:I have gathered information on an AI job, but to provide a more comprehensive answer, I should also look into AI trends.\\nAction: google_trends\\nAction Input: AI trends\\nObservation: Query: AI trends\\nDate From: Mar 10, 2024\\nDate To: Mar 15, 2025\\nMin Value: 37\\nMax Value: 100\\nAverage Value: 52.735849056603776\\nPercent Change: 65.21739130434783%\\nTrend values: 46, 44, 40, 40, 47, 46, 44, 42, 37, 42, 39, 41, 42, 42, 43, 46, 40, 48, 45, 42, 44, 45, 47, 47, 49, 49, 48, 51, 53, 48, 48, 50, 51, 50, 47, 54, 55, 53, 61, 59, 50, 43, 54, 65, 62, 63, 90, 79, 83, 100, 90, 75, 76\\nRising Related Queries: deepseek, deepseek ai, agentic ai, kling ai, ai humanizer free, how ai is transforming industries, latest programming languages 2025, understanding apis and their uses, cybersecurity basics for individuals and businesses, 5g smartphones, top skills to learn for career growth, the power of journaling for mental clarity, how to build better habits using science, ai powered home devices, premium audio systems, napkin ai, how to set and achieve smart goals, how blockchain works explained, introduction to cloud computing for beginners, ai trends 2025, ai trends 2024\\nTop Related Queries: trends in ai, google ai, google trends, ai trends 2024, what is ai, ai trends 2025, technology trends, new ai trends, current trends, ai tools, generative ai trends, chatgpt ai, generative ai, digital trends, ai generator, current trends in ai, video ai, ai news, ai trend, artificial intelligence, deepseek, deepseek ai, agentic ai, kling ai, ai humanizer free\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOpenAI] [7.17s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I now know the final answer\\nFinal Answer: Xu Wei, here's some information about AI jobs and trends:\\n\\n**AI Job Example:**\\n- **Job Title:** AI Content Reviewer\\n- **Company:** Outlier\\n- **Location:** Mason, OH (Remote)\\n- **Description:** This role involves evaluating and ranking AI-generated responses, crafting and refining prompts, and reviewing AI workflows to improve content quality. The position is flexible and freelance, with pay rates ranging from $15 to $35 USD per hour based on expertise and project needs.\\n\\n**AI Trends:**\\n- **Interest Growth:** AI trends have seen a significant increase in interest, with a 65.22% rise over the past year.\\n- **Rising Related Queries:** Some of the rising queries include \\\"deepseek,\\\" \\\"agentic ai,\\\" \\\"kling ai,\\\" \\\"ai humanizer free,\\\" and \\\"how AI is transforming industries.\\\"\\n- **Top Related Queries:** Popular topics include \\\"trends in AI,\\\" \\\"Google AI,\\\" \\\"AI trends 2024,\\\" \\\"generative AI trends,\\\" and \\\"AI news.\\\"\\n\\nThese insights should give you a good overview of the current landscape in AI jobs and trends.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": {\n",
      "            \"content\": []\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I now know the final answer\\nFinal Answer: Xu Wei, here's some information about AI jobs and trends:\\n\\n**AI Job Example:**\\n- **Job Title:** AI Content Reviewer\\n- **Company:** Outlier\\n- **Location:** Mason, OH (Remote)\\n- **Description:** This role involves evaluating and ranking AI-generated responses, crafting and refining prompts, and reviewing AI workflows to improve content quality. The position is flexible and freelance, with pay rates ranging from $15 to $35 USD per hour based on expertise and project needs.\\n\\n**AI Trends:**\\n- **Interest Growth:** AI trends have seen a significant increase in interest, with a 65.22% rise over the past year.\\n- **Rising Related Queries:** Some of the rising queries include \\\"deepseek,\\\" \\\"agentic ai,\\\" \\\"kling ai,\\\" \\\"ai humanizer free,\\\" and \\\"how AI is transforming industries.\\\"\\n- **Top Related Queries:** Popular topics include \\\"trends in AI,\\\" \\\"Google AI,\\\" \\\"AI trends 2024,\\\" \\\"generative AI trends,\\\" and \\\"AI news.\\\"\\n\\nThese insights should give you a good overview of the current landscape in AI jobs and trends.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 247,\n",
      "                \"prompt_tokens\": 1399,\n",
      "                \"total_tokens\": 1646\n",
      "              },\n",
      "              \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": {\n",
      "                \"content\": []\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0c14ba60-3bee-4782-9f59-2d805cbd86df-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 247,\n",
      "      \"prompt_tokens\": 1399,\n",
      "      \"total_tokens\": 1646\n",
      "    },\n",
      "    \"model_name\": \"qwen2.5-72b-instruct\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [7.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I now know the final answer\\nFinal Answer: Xu Wei, here's some information about AI jobs and trends:\\n\\n**AI Job Example:**\\n- **Job Title:** AI Content Reviewer\\n- **Company:** Outlier\\n- **Location:** Mason, OH (Remote)\\n- **Description:** This role involves evaluating and ranking AI-generated responses, crafting and refining prompts, and reviewing AI workflows to improve content quality. The position is flexible and freelance, with pay rates ranging from $15 to $35 USD per hour based on expertise and project needs.\\n\\n**AI Trends:**\\n- **Interest Growth:** AI trends have seen a significant increase in interest, with a 65.22% rise over the past year.\\n- **Rising Related Queries:** Some of the rising queries include \\\"deepseek,\\\" \\\"agentic ai,\\\" \\\"kling ai,\\\" \\\"ai humanizer free,\\\" and \\\"how AI is transforming industries.\\\"\\n- **Top Related Queries:** Popular topics include \\\"trends in AI,\\\" \\\"Google AI,\\\" \\\"AI trends 2024,\\\" \\\"generative AI trends,\\\" and \\\"AI news.\\\"\\n\\nThese insights should give you a good overview of the current landscape in AI jobs and trends.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [12.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Xu Wei, here's some information about AI jobs and trends:\\n\\n**AI Job Example:**\\n- **Job Title:** AI Content Reviewer\\n- **Company:** Outlier\\n- **Location:** Mason, OH (Remote)\\n- **Description:** This role involves evaluating and ranking AI-generated responses, crafting and refining prompts, and reviewing AI workflows to improve content quality. The position is flexible and freelance, with pay rates ranging from $15 to $35 USD per hour based on expertise and project needs.\\n\\n**AI Trends:**\\n- **Interest Growth:** AI trends have seen a significant increase in interest, with a 65.22% rise over the past year.\\n- **Rising Related Queries:** Some of the rising queries include \\\"deepseek,\\\" \\\"agentic ai,\\\" \\\"kling ai,\\\" \\\"ai humanizer free,\\\" and \\\"how AI is transforming industries.\\\"\\n- **Top Related Queries:** Popular topics include \\\"trends in AI,\\\" \\\"Google AI,\\\" \\\"AI trends 2024,\\\" \\\"generative AI trends,\\\" and \\\"AI news.\\\"\\n\\nThese insights should give you a good overview of the current landscape in AI jobs and trends.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#### your task ####\n",
    "# use a built-in tool in langchain to complete a task of your choice. \n",
    "# in the comment, please describe the task and the tool you used. \n",
    "# optional: try to use more than one tool in the same agent\n",
    "from langchain.agents import load_tools \n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=News)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, you are desired to help xu wei find a job. However, you are not good at finding a job, so you should use tools I provided to you: {keyword}\",\n",
    "        ),\n",
    "        (\"user\", \"{keyword}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # used to store the previous agent tool invocations and the corresponding tool outputs. \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "tools = [load_tools([\"google-trends\"], chat_model)[0], load_tools([\"google-jobs\"], chat_model)[0]]\n",
    "\n",
    "agent_chain = initialize_agent(tools, chat_model, agent=\"zero-shot-react-description\", prompt_template=prompt, verbose=True)\n",
    "\n",
    "set_debug(True)\n",
    "agent_chain.invoke(\"Tell xu wei sth about google ai-jobs and ai-trends.\")\n",
    "set_debug(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
